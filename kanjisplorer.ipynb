{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "kanjisplorer.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMhn2MWNOFhrc0anAqxsaoT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/thepelkus-too/notebook-test/blob/master/kanjisplorer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mi3ZN67cf39z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import argparse\n",
        "import sys\n",
        "import numpy as np\n",
        "import json\n",
        "import os\n",
        "import re\n",
        "from os.path import isfile, join\n",
        "import keras\n",
        "from keras.preprocessing import image\n",
        "from keras.applications.imagenet_utils import decode_predictions, preprocess_input\n",
        "from keras.models import Model\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.manifold import TSNE\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from scipy.spatial import distance\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QgE8u2QpgAwS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def process_arguments(args):\n",
        "    parser = argparse.ArgumentParser(description='tSNE on audio')\n",
        "    parser.add_argument('--images_path', action='store',\n",
        "                        help='path to directory of images')\n",
        "    parser.add_argument('--output_path', action='store',\n",
        "                        help='path to where to put output json file')\n",
        "    parser.add_argument('--num_dimensions', action='store', default=2,\n",
        "                        help='dimensionality of t-SNE points (default 2)')\n",
        "    parser.add_argument('--perplexity', action='store',\n",
        "                        default=30, help='perplexity of t-SNE (default 30)')\n",
        "    parser.add_argument('--learning_rate', action='store',\n",
        "                        default=150, help='learning rate of t-SNE (default 150)')\n",
        "    parser.add_argument('--saved_activations_path', action='store',\n",
        "                        help='path to saved activations, or where to save if not saved')\n",
        "    params = vars(parser.parse_args(args))\n",
        "    return params"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xmAynggggC1L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_image(path, input_shape):\n",
        "    img = image.load_img(path, target_size=input_shape)\n",
        "    x = image.img_to_array(img)\n",
        "    x = np.expand_dims(x, axis=0)\n",
        "    x = preprocess_input(x)\n",
        "    return x\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oAKzuwqdgF06",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def find_candidate_images(images_path):\n",
        "    \"\"\"\n",
        "    Finds all candidate images in the given folder and its sub-folders.\n",
        "\n",
        "    Returns:\n",
        "        images: a list of absolute paths to the discovered images.\n",
        "    \"\"\"\n",
        "    images = []\n",
        "    for root, dirs, files in os.walk(images_path):\n",
        "        for name in files:\n",
        "            file_path = os.path.abspath(os.path.join(root, name))\n",
        "            if ((os.path.splitext(name)[1]).lower() in ['.jpg', '.png', '.jpeg']):\n",
        "                images.append(file_path)\n",
        "    return images\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y5Iob1vrgLBM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def analyze_images(images_path, saved_activations_path):\n",
        "    # try to get activations from path first\n",
        "    activations_load_path = f'{saved_activations_path}_act.npy'\n",
        "    images_load_path = f'{saved_activations_path}_img.npy'\n",
        "    if isfile(activations_load_path) and isfile(images_load_path):\n",
        "        activations = np.load(activations_load_path)\n",
        "        images = np.load(images_load_path)\n",
        "    else:\n",
        "        # make feature_extractor\n",
        "        model = keras.applications.VGG16(weights='imagenet', include_top=True)\n",
        "        feat_extractor = Model(\n",
        "            inputs=model.input, outputs=model.get_layer(\"fc2\").output)\n",
        "        input_shape = model.input_shape[1:3]\n",
        "        # get images\n",
        "        candidate_images = find_candidate_images(images_path)\n",
        "        # analyze images and grab activations\n",
        "        activations = []\n",
        "        images = []\n",
        "        combined = []\n",
        "        for idx, image_path in enumerate(candidate_images):\n",
        "            file_path = join(images_path, image_path)\n",
        "            img = get_image(file_path, input_shape)\n",
        "            if img is not None:\n",
        "                print(\"getting activations for %s %d/%d\" %\n",
        "                      (image_path, idx, len(candidate_images)))\n",
        "                acts = feat_extractor.predict(img)[0]\n",
        "                activations.append(acts)\n",
        "                images.append(image_path)\n",
        "                combined.append(\n",
        "                    {\"imagepath\": image_path, \"activations\": activations})\n",
        "\n",
        "        # cache activations\n",
        "        # TODO: use data path here\n",
        "        np.save(saved_activations_path + \"_act\", activations)\n",
        "        np.save(saved_activations_path + \"_img\", images)\n",
        "\n",
        "    return images, activations"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "foaidQQDgNcD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def pca_from_activations(images, activations, dimensions=300):\n",
        "    # run PCA firt\n",
        "    print(\"Running PCA on %d images...\" % len(activations))\n",
        "    features = np.array(activations)\n",
        "\n",
        "    pca_pipeline = make_pipeline(\n",
        "        StandardScaler(), PCA(n_components=dimensions))\n",
        "    # pca = PCA(n_components=dimensions)\n",
        "    pca_pipeline.fit(features)\n",
        "    pca_features = pca_pipeline.transform(features)\n",
        "    return images, pca_features\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k5ISmnEmgPYC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def kanji_for_index(kanjis, images, i):\n",
        "    image_filename = images[i]\n",
        "    index_from_image_filename = int(\n",
        "        re.search(\"(\\d{4})\", image_filename).groups()[0])\n",
        "\n",
        "    return kanjis[index_from_image_filename]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d1heXm_ngRLj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def nearest_kanji(full_data, images, kanjis, start, end, num_neighbors):\n",
        "    working_data = full_data[start:end]\n",
        "    nbrs = NearestNeighbors(n_neighbors=num_neighbors,\n",
        "                            algorithm='ball_tree').fit(working_data)\n",
        "    distances, indices = nbrs.kneighbors(working_data)\n",
        "    neighbors = []\n",
        "    for indices_x in indices:\n",
        "        try:\n",
        "            chars = [kanji_for_index(kanjis, images[start:end], x)\n",
        "                     for x in indices_x]\n",
        "            neighbors = neighbors + [chars]\n",
        "        except:\n",
        "            images_nums = np.array([images[start:end][x] for x in indices_x])\n",
        "            print(f'BORKED {indices_x} {images_nums}')\n",
        "\n",
        "    return neighbors\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-CPGW7GSgTwU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def run_tsne(images_path, output_path, tsne_dimensions, tsne_perplexity, tsne_learning_rate, saved_activations_path):\n",
        "    images, activations = analyze_images(images_path, saved_activations_path)\n",
        "\n",
        "    f = open('kanjis.json')\n",
        "    kanjis = json.load(f)\n",
        "\n",
        "    # start = 0\n",
        "    # end = len(activations)\n",
        "\n",
        "    # activations_nn = nearest_kanji(activations, images, kanjis, start, end, 7)\n",
        "    # for ann in activations_nn:\n",
        "    #     print(ann)\n",
        "\n",
        "    # sys.exit()\n",
        "\n",
        "    images, pca_features_2d = pca_from_activations(images, activations, 2)\n",
        "    \n",
        "    # pca_nn = nearest_kanji(pca_features_2d, images, kanjis, start, end, 7)\n",
        "\n",
        "    for (ann, pcann) in zip(activations_nn, pca_nn):\n",
        "        print(ann)\n",
        "        print(pcann)\n",
        "\n",
        "    # Let's look at X axis\n",
        "    # for entry in sorted(filter(lambda x: x[1][1] > -1 and x[1][1] < 1, enumerate(pca_features_2d)), key=lambda x: x[1][0]):\n",
        "    #     x = entry[1][0]\n",
        "    #     y = entry[1][1]\n",
        "    #     i = entry[0]\n",
        "    #     kanji = kanji_for_index(kanjis, images, i)\n",
        "    #     print(f'{x} {y} {kanji}')\n",
        "\n",
        "    # Let's look at Y axis\n",
        "    # for entry in sorted(filter(lambda x: x[1][0] > -1 and x[1][0] < 1, enumerate(pca_features_2d)), key=lambda x: x[1][1]):\n",
        "    #     x = entry[1][0]\n",
        "    #     y = entry[1][1]\n",
        "    #     i = entry[0]\n",
        "    #     kanji = kanji_for_index(kanjis, images, i)\n",
        "    #     print(f'{x} {y} {kanji}')\n",
        "\n",
        "    sys.exit()\n",
        "\n",
        "    images, pca_features = pca_from_activations(\n",
        "        images, activations)\n",
        "    print(\"Running t-SNE on %d images...\" % len(images))\n",
        "    X = np.array(pca_features)\n",
        "    tsne = TSNE(n_iter=2000, n_components=tsne_dimensions, learning_rate=tsne_learning_rate,\n",
        "                perplexity=tsne_perplexity, verbose=2).fit_transform(X)\n",
        "    # save data to json\n",
        "    data = []\n",
        "    for i, f in enumerate(images):\n",
        "        point = [float((tsne[i, k] - np.min(tsne[:, k]))/(np.max(tsne[:, k]\n",
        "                                                                 ) - np.min(tsne[:, k]))) for k in range(tsne_dimensions)]\n",
        "        data.append({\"path\": os.path.abspath(\n",
        "            join(images_path, images[i])), \"point\": point})\n",
        "    with open(output_path, 'w') as outfile:\n",
        "        json.dump(data, outfile)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GVyyIU7Jfia0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "images_path = \"./jpg\"\n",
        "output_path = \"tsneCoords.json\"\n",
        "tsne_dimensions = 3\n",
        "tsne_perplexity = 50\n",
        "tsne_learning_rate = 150\n",
        "saved_activations_path = \"full\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XiEkLPBRkB0r",
        "colab_type": "code",
        "outputId": "a9d63aa2-2f08-4ab0-a378-55183c92aa6c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 351
        }
      },
      "source": [
        "run_tsne(images_path,\n",
        "         output_path,\n",
        "         tsne_dimensions,\n",
        "         tsne_perplexity,\n",
        "         tsne_learning_rate,\n",
        "         saved_activations_path)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels.h5\n",
            "553467904/553467096 [==============================] - 8s 0us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-2d141d56cd4d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m          \u001b[0mtsne_perplexity\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m          \u001b[0mtsne_learning_rate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m          saved_activations_path)\n\u001b[0m",
            "\u001b[0;32m<ipython-input-13-4ac206c9d539>\u001b[0m in \u001b[0;36mrun_tsne\u001b[0;34m(images_path, output_path, tsne_dimensions, tsne_perplexity, tsne_learning_rate, saved_activations_path)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0manalyze_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaved_activations_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'kanjis.json'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mkanjis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'kanjis.json'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XUoetvdUfw7I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}